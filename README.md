# ğŸ‰ Three-Dragon Ante AI

This project implements an AI agent that plays **Three-Dragon Ante (3DA)**, a strategic fantasy card game of bluffing and risk. The AI uses **Monte Carlo Tree Search (MCTS)** and **Bayesian inference** to make intelligent, forward-looking decisions during gameplay.

---

## ğŸ® Game Summary

Three-Dragon Ante is a poker-style game where players:
- **Ante** a card at the start of each gambit
- Take turns playing dragon cards into their **flight**
- Trigger **powers** based on the type and color of cards
- Win or lose gold based on total flight strength and triggered effects

The game continues across multiple gambits until a player is eliminated or a winning condition is met.

---

## ğŸ¤– AI Features

The AI plays as one of the players in the game and makes decisions based on simulations and predictions. It can:
- Choose which **card to ante**
- Decide whether to **give up a card or gold** when prompted by card effects
- Select which **card to play** during its turn
- **Predict opponent card strength** using a Bayesian model based on cards already played

---

## ğŸ§  AI Architecture

### ğŸ§© Game State Representation

Each simulation node contains a full game state, represented by a `TDA` object that tracks:
- Each player's **gold**, **card count**, and **flight**
- The AI player's **hand** and **gold**
- The current **ante** (cards + gold)
- Whose **turn** it is
- The **last played card**

All simulations **deep copy** this state to avoid side effects.

### ğŸŒ€ MCTS Overview

- Each node corresponds to a full game state
- Simulations run until the **end of the current gambit**
- **Random card draws** are handled via sampling or averaged value (e.g., strength = 7)
- Only **AI turns are used for node selection and backpropagation**
- Scoring is based on:
  ```
  score = coins + estimated coin value of cards remaining in hand
  ```

### ğŸ“Š Opponent Modeling

Opponent card strength is estimated using Bayesian updates:
- Initial distribution assumes a mean of 7 (values from 1 to 13)
- Each played card updates the posterior
- AI uses this to predict likely future card values for opponents

---

## ğŸ“ Project Structure

```plaintext
3DA/
â”œâ”€â”€ game/
â”‚   â”œâ”€â”€ AIPlayer.py       # AI-specific player logic
â”‚   â”œâ”€â”€ Player.py         # Base player class
â”‚   â”œâ”€â”€ TDA.py            # Game state and rule enforcement
â”‚   â”œâ”€â”€ Cards.py          # Dragon card powers (basic colors)
â”‚   â”œâ”€â”€ Card.py           # Card base class
â”‚   â”œâ”€â”€ Ante.py           # Ante mechanics
â”‚   â”œâ”€â”€ Flight.py         # Flight logic and resolution
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ MCTS/
â”‚   â”œâ”€â”€ MCTS.py           # Core MCTS algorithm
â”‚   â”œâ”€â”€ Node.py           # Tree node representation
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ game.py               # Main entry point to play a full game
â”œâ”€â”€ gameTests.py          # Basic test harness
â””â”€â”€ README.md             # You're here
```

---

## ğŸ› ï¸ Requirements

- Python 3.10+
- No external dependencies

---

## ğŸš€ Running the Project

To run a full AI game simulation:

```bash
python3 game.py
```

To run any tests or debug gameplay behavior:

```bash
python3 gameTests.py
```

---

## âš ï¸ Limitations

- Deck is currently assumed to be **infinite** (drawn cards may repeat)
- **Legendary and Mortal** card types are not yet implemented
- Opponents use **random or simple heuristics**
- Some card interactions may be simplified for now

---

## ğŸ›£ï¸ Future Improvements

- Implement **finite deck mechanics**
- Add full support for **Legendary and Mortal** cards
- Improve opponent behavior using **learned policies or heuristics**
- Expand power resolution to support edge cases and chaining
- Visualize game state and MCTS decision tree for debugging

---

## ğŸ“¬ Contributions

Open to ideas, contributions, or feedback! Feel free to fork this repo, open issues, or suggest improvements.
